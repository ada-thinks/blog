国际银行智能问答助手（LLM + 知识库）前端全链路研发
一、项目定位
为某国际银行零售与对公业务条线，开发基于企业级大模型的智能问答助手，核心解决银行员工 “业务规则查询繁琐、客户问题应答不精准、知识库沉淀与调用低效” 的痛点。前端负责搭建 “知识库管理 + 模型训练配置 + 智能对话交互 + 反馈闭环” 的一体化界面，支撑银行员工通过自然语言快速查询信贷政策、合规条款、产品说明等核心内容，同时通过用户反馈持续优化模型效果，保障金融场景下的回答准确性与合规性。
二、核心职责
对话交互层开发：主导智能问答助手前端架构设计，基于 Vue3 + TypeScript + Pinia 实现流式对话、引用高亮、上下文关联等核心功能，保障金融级场景的交互稳定性与流畅性；
知识库管理模块开发：负责文档上传、解析、分块、标签管理的前端实现，支持 PDF/Word/Excel 等多格式金融文档批量上传，对接后端向量数据库完成文档向量化存储；
模型训练配置界面开发：设计可视化的模型微调配置页，支持员工选择指定知识库、设置训练参数（迭代次数、学习率）、启动 / 暂停训练任务，并实时展示训练进度与日志；
RAG 增强功能前端落地：深度对接后端 RAG（检索增强生成）链路，实现 “检索结果→引用标注→回答生成” 的前端联动，确保大模型回答可溯源、可核验；
反馈闭环体系搭建：开发点赞、踩、人工纠错等反馈功能，将用户交互数据实时同步至后端模型优化链路，助力模型持续迭代。
